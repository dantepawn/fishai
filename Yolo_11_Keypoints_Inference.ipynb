{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2S2wlGQVMgvt"
      },
      "source": [
        "# Keypoints generation with YOLO11"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-cLI2l_JPX1d"
      },
      "outputs": [],
      "source": [
        "# Mount drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gqA5HrfEMiLA",
        "outputId": "2284861f-d87d-4e52-c88c-91cf36fafa24"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/1.1 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━\u001b[0m \u001b[32m1.0/1.1 MB\u001b[0m \u001b[31m28.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.1/1.1 MB\u001b[0m \u001b[31m20.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install -q ultralytics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wk4O6B3GM-HM",
        "outputId": "9d9d179d-8c92-461f-a711-caeadecd95e1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Creating new Ultralytics Settings v0.0.6 file ✅ \n",
            "View Ultralytics Settings with 'yolo settings' or at '/root/.config/Ultralytics/settings.json'\n",
            "Update Settings with 'yolo settings key=value', i.e. 'yolo settings runs_dir=path/to/dir'. For help see https://docs.ultralytics.com/quickstart/#ultralytics-settings.\n"
          ]
        }
      ],
      "source": [
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "from pathlib import Path\n",
        "\n",
        "from random import sample\n",
        "\n",
        "import cv2\n",
        "from ultralytics import YOLO"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-Va7sBFtwnaf"
      },
      "outputs": [],
      "source": [
        "    model = YOLO(\"/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/YOLO/runs/pose/train17/weights/best.pt\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djxp3rNexsnG"
      },
      "outputs": [],
      "source": [
        "!mkdir \"/content/YOLO_INFERENCE/\"\n",
        "!mkdir \"/content/labels/\"\n",
        "!mkdir \"/content/low_confidance/\"\n",
        "!mkdir \"/content/low_confidance/labels/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qDdxh3XaFwMz"
      },
      "outputs": [],
      "source": [
        "source_images = \"/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/ORATE singole 2\"\n",
        "target_folder = \"/content/YOLO_INFERENCE/\"\n",
        "labels_folder = \"/content/labels/\"\n",
        "low_confidance_folder = \"/content/low_confidance/\"\n",
        "low_confidance_folder_labels = \"/content/low_confidance/labels/\"\n",
        "source_images = list(Path(source_images).glob(\"*.jpg\"))\n",
        "sample_source_images = sample(source_images, 100)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7e7YIEpesjMp"
      },
      "source": [
        "### only 0 and 1 lens are used for keypoints detection as the segmentation will detect the corresponding mask in lens 3 and 2 respectilvely"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9JUo8hwSr3Gp"
      },
      "outputs": [],
      "source": [
        "source_images_0 = [x for x in sample_source_images if \"l0\" in str(x)]\n",
        "source_images_1= [x for x in sample_source_images if \"l1\" in str(x)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VigvKdg2vJe",
        "outputId": "17f93f49-4e2e-4caf-e14d-6049213d580d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "0: 1024x800 7 fishs, 123.9ms\n",
            "1: 1024x800 9 fishs, 123.9ms\n",
            "2: 1024x800 3 fishs, 123.9ms\n",
            "3: 1024x800 9 fishs, 123.9ms\n",
            "4: 1024x800 4 fishs, 123.9ms\n",
            "5: 1024x800 6 fishs, 123.9ms\n",
            "6: 1024x800 13 fishs, 123.9ms\n",
            "7: 1024x800 4 fishs, 123.9ms\n",
            "8: 1024x800 1 fish, 123.9ms\n",
            "9: 1024x800 5 fishs, 123.9ms\n",
            "10: 1024x800 4 fishs, 123.9ms\n",
            "11: 1024x800 9 fishs, 123.9ms\n",
            "12: 1024x800 4 fishs, 123.9ms\n",
            "13: 1024x800 3 fishs, 123.9ms\n",
            "14: 1024x800 5 fishs, 123.9ms\n",
            "15: 1024x800 3 fishs, 123.9ms\n",
            "16: 1024x800 9 fishs, 123.9ms\n",
            "17: 1024x800 6 fishs, 123.9ms\n",
            "18: 1024x800 10 fishs, 123.9ms\n",
            "19: 1024x800 3 fishs, 123.9ms\n",
            "20: 1024x800 5 fishs, 123.9ms\n",
            "21: 1024x800 4 fishs, 123.9ms\n",
            "22: 1024x800 8 fishs, 123.9ms\n",
            "23: 1024x800 8 fishs, 123.9ms\n",
            "24: 1024x800 7 fishs, 123.9ms\n",
            "25: 1024x800 5 fishs, 123.9ms\n",
            "26: 1024x800 5 fishs, 123.9ms\n",
            "27: 1024x800 (no detections), 123.9ms\n",
            "28: 1024x800 4 fishs, 123.9ms\n",
            "29: 1024x800 4 fishs, 123.9ms\n",
            "30: 1024x800 4 fishs, 123.9ms\n",
            "31: 1024x800 5 fishs, 123.9ms\n",
            "32: 1024x800 4 fishs, 123.9ms\n",
            "33: 1024x800 3 fishs, 123.9ms\n",
            "34: 1024x800 2 fishs, 123.9ms\n",
            "35: 1024x800 5 fishs, 123.9ms\n",
            "36: 1024x800 2 fishs, 123.9ms\n",
            "37: 1024x800 9 fishs, 123.9ms\n",
            "38: 1024x800 3 fishs, 123.9ms\n",
            "39: 1024x800 7 fishs, 123.9ms\n",
            "40: 1024x800 5 fishs, 123.9ms\n",
            "41: 1024x800 6 fishs, 123.9ms\n",
            "42: 1024x800 1 fish, 123.9ms\n",
            "43: 1024x800 6 fishs, 123.9ms\n",
            "44: 1024x800 6 fishs, 123.9ms\n",
            "45: 1024x800 4 fishs, 123.9ms\n",
            "Speed: 8.4ms preprocess, 123.9ms inference, 10.0ms postprocess per image at shape (1, 3, 1024, 800)\n"
          ]
        }
      ],
      "source": [
        "results = model.predict(sample_source_images)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_Z8BXVk87bH7"
      },
      "outputs": [],
      "source": [
        "def generate_labels(results, target_folder, labels_folder , confidence=.2):\n",
        "    \"\"\n",
        "    for result in results:\n",
        "        image_file = f\"{target_folder}{Path(result.path).stem}.jpg\"\n",
        "        result.save(image_file , line_width = 8 ,kpt_radius = 10 )\n",
        "        labels_file = f\"{labels_folder}{Path(result.path).stem}.txt\"\n",
        "        height, width, _ = cv2.imread(image_file).shape\n",
        "        with open(labels_file , 'w') as label_file:\n",
        "            for box, keypoint, conf in zip(result.boxes.xyxy, result.keypoints.xy, result.boxes.conf ):\n",
        "                if conf >= confidence:\n",
        "                #save them in yolo format\n",
        "                    box_width = box[2] - box[0]\n",
        "                    box_height = box[3] - box[1]\n",
        "                    box_center_x = box[0] + box_width / 2\n",
        "                    box_center_y = box[1] + box_height / 2\n",
        "\n",
        "                    # Normalize the box coordinates\n",
        "                    box_center_x /= width\n",
        "                    box_center_y /= height\n",
        "                    box_width /= width\n",
        "                    box_height /= height\n",
        "\n",
        "                    box_str = f\"0 {box_center_x} {box_center_y} {box_width} {box_height}\"\n",
        "\n",
        "                    keypoints_str = \" \".join([f\"{x / width} {y / height}\" for x, y in keypoint])\n",
        "\n",
        "                    label_file.write(f\"{box_str} {keypoints_str}\\n\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "t3mpfR0ON23P"
      },
      "outputs": [],
      "source": [
        "def generate_labels(results, target_folder, labels_folder, confidence: float = 0.2, line_width: int = 8, kpt_radius: int = 10) -> None:\n",
        "    \"\"\"\n",
        "    Generate YOLO-style label files with bounding boxes and keypoints from detection results.\n",
        "\n",
        "    Each detection result is saved as:\n",
        "      - An annotated image in `target_folder`.\n",
        "      - A `.txt` file in `labels_folder` containing YOLO-format annotations:\n",
        "        class_id center_x center_y width height kpt1_x kpt1_y ... kptN_x kptN_y\n",
        "\n",
        "    Bounding boxes and keypoints are normalized to [0, 1] relative to image size.\n",
        "\n",
        "    Args:\n",
        "        results (list): List of detection results, each containing `.path`, `.boxes.xyxy`, `.boxes.conf`, and `.keypoints.xy`.\n",
        "        target_folder (str or Path): Directory where annotated images will be saved.\n",
        "        labels_folder (str or Path): Directory where YOLO-format label files will be saved.\n",
        "        confidence (float, optional): Minimum confidence threshold for saving a detection. Defaults to 0.2.\n",
        "        line_width (int, optional): Line thickness for saved bounding box annotations. Defaults to 8.\n",
        "        kpt_radius (int, optional): Radius for keypoint drawing. Defaults to 10.\n",
        "\n",
        "    Returns:\n",
        "        None\n",
        "    \"\"\"\n",
        "    target_folder = Path(target_folder)\n",
        "    labels_folder = Path(labels_folder)\n",
        "    target_folder.mkdir(parents=True, exist_ok=True)\n",
        "    labels_folder.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "    for result in results:\n",
        "        image_file = target_folder / f\"{Path(result.path).stem}.jpg\"\n",
        "        labels_file = labels_folder / f\"{Path(result.path).stem}.txt\"\n",
        "\n",
        "        # Save annotated image\n",
        "        result.save(str(image_file), line_width=line_width, kpt_radius=kpt_radius)\n",
        "\n",
        "        # Load image size\n",
        "        img = cv2.imread(str(image_file))\n",
        "        if img is None:\n",
        "            print(f\"[WARN] Could not read {image_file}, skipping.\")\n",
        "            continue\n",
        "        height, width, _ = img.shape\n",
        "\n",
        "        with open(labels_file, \"w\") as f:\n",
        "            for box, keypoint, conf in zip(result.boxes.xyxy, result.keypoints.xy, result.boxes.conf):\n",
        "                if conf < confidence:\n",
        "                    continue\n",
        "\n",
        "                # Bounding box in YOLO format (normalized)\n",
        "                box_width = (box[2] - box[0]) / width\n",
        "                box_height = (box[3] - box[1]) / height\n",
        "                box_center_x = (box[0] + (box[2] - box[0]) / 2) / width\n",
        "                box_center_y = (box[1] + (box[3] - box[1]) / 2) / height\n",
        "\n",
        "                # Format bounding box\n",
        "                box_str = f\"0 {box_center_x:.6f} {box_center_y:.6f} {box_width:.6f} {box_height:.6f}\"\n",
        "\n",
        "                # Format keypoints (normalized)\n",
        "                keypoints_str = \" \".join([f\"{x / width:.6f} {y / height:.6f}\" for x, y in keypoint])\n",
        "\n",
        "                f.write(f\"{box_str} {keypoints_str}\\n\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Ng7UjGfc86Ut"
      },
      "outputs": [],
      "source": [
        "generate_labels(results, target_folder = \"./YOLO_INFERENCE/\", labels_folder=\"./labels/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "X5YGXxV69jPk",
        "outputId": "67926f62-5c71-4976-d2cf-b935256f1791"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/Data_Inference/YOLO_INFERENCE20/'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# copy the labels folder to /content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/YOLO...\n",
        "import shutil\n",
        "shutil.copytree(labels_folder, \"/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/Data_Inference/YOLO_INFERENCE20/\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TBsFb-TKbAOo"
      },
      "source": [
        "# Inference for Validation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B07Uh640bKAc"
      },
      "outputs": [],
      "source": [
        "!mkdir \"/content/YOLO_INFERENCE/\"\n",
        "!mkdir \"/content/labels/\"\n",
        "!mkdir \"/content/low_confidance/\"\n",
        "!mkdir \"/content/low_confidance/labels/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IoFtOkrXbPaw"
      },
      "outputs": [],
      "source": [
        "source_images_0 = \"/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/ORATE (Capraia)_Luglio 25\"\n",
        "source_images_1 = \"/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/SPIGOLE (Capraia)_Ottobre 24 con dati biometrici pesca\"\n",
        "source_images_2 = \"/content/drive/MyDrive/2023_24 Prototype 2.0/sagome PESCI/Sagome in acqua\"\n",
        "source_images_3 = \"/content/drive/MyDrive/2023_24 Prototype 2.0/sagome PESCI/Sagome a terra distanza nota\"\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FQJk57_kduYb"
      },
      "source": [
        "### split images into lenses"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fuFgM_JtfCtl"
      },
      "outputs": [],
      "source": [
        "source_image = list(Path(source_images_0).glob(\"*.png\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LFZPvdgDfwVH"
      },
      "outputs": [],
      "source": [
        "!mkdir fish_images\n",
        "!mkdir \"/content/YOLO_INFERENCE/\"\n",
        "!mkdir \"/content/labels/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nVCFlxBkdkdT"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "for i , f in enumerate(source_image):\n",
        "    fname = str(f)\n",
        "    img = cv2.imread(fname)\n",
        "    height, width = img.shape[:2]\n",
        "    l0 = img[:height // 2, :width // 2]\n",
        "    l3 = img[:height // 2, width // 2:]\n",
        "    l1 = img[height // 2:, :width // 2]\n",
        "    l2 = img[height // 2:, width // 2:]\n",
        "    correct_l0 = cv2.rotate(l0, cv2.ROTATE_90_CLOCKWISE)\n",
        "    correct_l1 = cv2.rotate(l1, cv2.ROTATE_90_CLOCKWISE)\n",
        "    correct_l2 = cv2.rotate(l2, cv2.ROTATE_90_CLOCKWISE)\n",
        "    correct_l3 = cv2.rotate(l3, cv2.ROTATE_90_CLOCKWISE)\n",
        "    cv2.imwrite(f\"./fish_images/{f.stem}_l0.jpg\", correct_l0)\n",
        "    cv2.imwrite(f\"./fish_images/{f.stem}_l1.jpg\", correct_l1)\n",
        "    cv2.imwrite(f\"./fish_images/{f.stem}_l2.jpg\", correct_l2)\n",
        "    cv2.imwrite(f\"./fish_images/{f.stem}_l3.jpg\", correct_l3)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YgTPB75Giwyf"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kRqv2YtGlzFh"
      },
      "outputs": [],
      "source": [
        "fish = Path('fish_images/').glob('*.*')\n",
        "# only select the 0 and 1 lenses\n",
        "fish = [x for x in fish if \"l0\" in str(x) or \"l1\" in str(x)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6EeipmRtmqRK",
        "outputId": "1d9dce7c-6414-4910-db94-b666d7e162bb"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "324"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(fish)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EjD57YCWpSnP"
      },
      "outputs": [],
      "source": [
        "# clear gpu ram\n",
        "#import torch\n",
        "#torch.cuda.empty_cache()\n",
        "\n",
        "# Define a batch size that fits into your GPU memory\n",
        "batch_size = 32 # You might need to adjust this value based on your GPU\n",
        "\n",
        "# Process images in batches\n",
        "results = []\n",
        "for i in tqdm(range(0, len(fish), batch_size)):\n",
        "    batch = fish[i:i + batch_size]\n",
        "    batch_results = model.predict(batch)\n",
        "    results.extend(batch_results)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z-n9PDhlpzLN"
      },
      "outputs": [],
      "source": [
        "generate_labels(results, target_folder = \"./YOLO_INFERENCE/\", labels_folder=\"./labels/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SbY5jvA6b6yj"
      },
      "outputs": [],
      "source": [
        "target_folder = \"/content/ORATE25/\"\n",
        "labels_folder = \"/content/labels/\"\n",
        "low_confidance_folder = \"/content/low_confidance/\"\n",
        "low_confidance_folder_labels = \"/content/low_confidance/labels/\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wdyrB4mucJTv"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/ORATE25.zip /content/orate25"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nUza63jvrVdn"
      },
      "source": [
        "# Spigole"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zoJSo_cQi34t"
      },
      "outputs": [],
      "source": [
        "!mkdir fish_images\n",
        "!mkdir \"/content/YOLO_INFERENCE/\"\n",
        "!mkdir \"/content/labels/\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "em2QZHOOt0Xz"
      },
      "outputs": [],
      "source": [
        "source_image = list(Path(source_images_1).glob(\"*/*.*\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "C3DobX9MuWZ6"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xWEo3i3Nt6Ad",
        "outputId": "166d75a6-a66b-411d-ba9f-4d52775ed0dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/SPIGOLE (Capraia)_Ottobre 24 con dati biometrici pesca/Gabbia7_shut8_foc16_iso300_600_nuvoloso_12.00/Spigole capraia_23-10-24.xlsx\n",
            "/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/SPIGOLE (Capraia)_Ottobre 24 con dati biometrici pesca/Gabbia7_shut8_foc16_iso300_600_nuvoloso_12.00/composizione Gabbia 7 (ottobre2024) Spigole.xlsx\n",
            "/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/SPIGOLE (Capraia)_Ottobre 24 con dati biometrici pesca/Gabbia7_shut8_foc16_iso300_600_nuvoloso_12.00/distribuzione pesi Gabbia 7 (ottobre2024) Spigole.xlsx\n",
            "/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/SPIGOLE (Capraia)_Ottobre 24 con dati biometrici pesca/Gabbia8_shut8_foc16_iso300_600_nuvoloso_14.00/distribuzione pesi startup israeliana.xlsx\n"
          ]
        }
      ],
      "source": [
        "for i , f in enumerate(source_image):\n",
        "    try :\n",
        "        fname = str(f)\n",
        "        img = cv2.imread(fname)\n",
        "        height, width = img.shape[:2]\n",
        "        l0 = img[:height // 2, :width // 2]\n",
        "        l3 = img[:height // 2, width // 2:]\n",
        "        l1 = img[height // 2:, :width // 2]\n",
        "        l2 = img[height // 2:, width // 2:]\n",
        "        correct_l0 = cv2.rotate(l0, cv2.ROTATE_90_CLOCKWISE)\n",
        "        correct_l1 = cv2.rotate(l1, cv2.ROTATE_90_CLOCKWISE)\n",
        "        correct_l2 = cv2.rotate(l2, cv2.ROTATE_90_CLOCKWISE)\n",
        "        correct_l3 = cv2.rotate(l3, cv2.ROTATE_90_CLOCKWISE)\n",
        "        cv2.imwrite(f\"./fish_images/{f.stem}_l0.jpg\", correct_l0)\n",
        "        cv2.imwrite(f\"./fish_images/{f.stem}_l1.jpg\", correct_l1)\n",
        "        cv2.imwrite(f\"./fish_images/{f.stem}_l2.jpg\", correct_l2)\n",
        "        cv2.imwrite(f\"./fish_images/{f.stem}_l3.jpg\", correct_l3)\n",
        "    except :\n",
        "        print(f)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ilPF70I_uSbV"
      },
      "outputs": [],
      "source": [
        "fish = Path('fish_images/').glob('*.*')\n",
        "# only select the 0 and 1 lenses\n",
        "fish = [x for x in fish if \"l0\" in str(x) or \"l1\" in str(x)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9iCyX6Qouuut",
        "outputId": "a88abd9e-5a97-480e-cfbe-455a32475979"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "424"
            ]
          },
          "execution_count": 36,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(fish)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wFVISC6SxynQ"
      },
      "outputs": [],
      "source": [
        "# clear gpu ram\n",
        "#import torch\n",
        "#torch.cuda.empty_cache()\n",
        "\n",
        "# Define a batch size that fits into your GPU memory\n",
        "batch_size = 32 # You might need to adjust this value based on your GPU\n",
        "\n",
        "# Process images in batches\n",
        "results = []\n",
        "for i in tqdm(range(0, len(fish), batch_size)):\n",
        "    batch = fish[i:i + batch_size]\n",
        "    batch_results = model.predict(batch)\n",
        "    results.extend(batch_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Yt60DIbY0s0E"
      },
      "source": [
        "# save to drive"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bJ030nro0PVL"
      },
      "outputs": [],
      "source": [
        "generate_labels(results, target_folder = \"./YOLO_INFERENCE/\", labels_folder=\"./labels/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "429dvGQ708cF",
        "outputId": "78da546c-6432-4f9b-8a37-2495c3c97a0c"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/Data_Inference/spigole24/'"
            ]
          },
          "execution_count": 39,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# copy the labels folder to /content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/YOLO...\n",
        "import shutil\n",
        "shutil.copytree(\"/content/labels_spigole24\", \"/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/Data_Inference/spigole24/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 36
        },
        "id": "F8Ug0ZFZ1MB4",
        "outputId": "451cc0ac-5e3c-477a-e093-d4e4e2c1f060"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/Data_Inference/orate25/'"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "# copy the labels folder to /content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/YOLO...\n",
        "import shutil\n",
        "shutil.copytree(\"/content/labels_orate25\", \"/content/drive/MyDrive/2023_24 Prototype 2.0/PESCI/Keypoints/Data_Inference/orate25/\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b4n9IHI31hUA"
      },
      "outputs": [],
      "source": [
        "!zip -r /content/spigole24.zip /content/spigole24_predictions/"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
